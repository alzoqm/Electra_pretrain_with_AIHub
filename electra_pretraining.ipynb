{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrXt5YozeOSy"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install kaggle\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfsTVqoQs-33",
        "outputId": "2abf6e74-f2c9-4011-844d-cecfd3907fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-784wLveTuJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba8JBSLIellP"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPZ6t5_CetRE",
        "outputId": "e0a22bc9-50a5-4402-a508-4d805cb7e2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ai-hub-encode-dataset.zip to /content\n",
            "100% 3.06G/3.07G [00:33<00:00, 82.2MB/s]\n",
            "100% 3.07G/3.07G [00:33<00:00, 98.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d alzoqm/ai-hub-encode-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVvx9jsZeyxM"
      },
      "outputs": [],
      "source": [
        "!unzip /content/ai-hub-encode-dataset.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vqh_PSXe-q8"
      },
      "outputs": [],
      "source": [
        "!rm /content/ai-hub-encode-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LAYFjONfTTT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "import transformers\n",
        "import random\n",
        "import os\n",
        "import tensorflow.distribute as tfd\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HwiryernzYqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "majh84NBgbY3",
        "outputId": "0324f74a-745f-4d7f-a07f-c103fcf60ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46Gb070sfeNj"
      },
      "outputs": [],
      "source": [
        "vocab = transformers.BertTokenizer('/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/vocab.txt', do_lower_case=False, strip_accents=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_mA-I37glnp",
        "outputId": "1d6ae089-a811-4a10-dc30-6318f9efc9da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3V_zoGbgpLs"
      },
      "outputs": [],
      "source": [
        "import electra_model as electra\n",
        "import make_pretrain_dataset_step2 as dataset_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFf99rNbgfNO"
      },
      "outputs": [],
      "source": [
        "#model hyper parameter는 electra small++과 동일하게 설정\n",
        "config = {}\n",
        "config['num_classes'] = 2\n",
        "config['max_len'] = 512\n",
        "config['seg_type'] = 2\n",
        "config['vocab_size'] = 32200\n",
        "config['gen_num_layers'] = 12\n",
        "config['gen_dff'] = 1024\n",
        "config['gen_d_model'] = 256\n",
        "config['gen_emb_size'] = 128\n",
        "config['gen_num_heads'] = 4\n",
        "config['gen_dropout'] = 0.1\n",
        "config['dis_num_layers'] = 12\n",
        "config['dis_dff'] = 1024\n",
        "config['dis_d_model'] = 256\n",
        "config['dis_emb_size'] = 128\n",
        "config['dis_num_heads'] = 4\n",
        "config['dis_dropout'] = 0.1\n",
        "config['dis_lambda'] = 50\n",
        "config['batch_size'] = 512\n",
        "config['lr'] = 5e-4\n",
        "config['epoch'] = 10\n",
        "\n",
        "#base parameter\n",
        "# config = {}\n",
        "# config['num_classes'] = 2\n",
        "# config['max_len'] = 512\n",
        "# config['seg_type'] = 2\n",
        "# config['vocab_size'] = 32200\n",
        "# config['gen_num_layers'] = 12\n",
        "# config['gen_dff'] = 1024\n",
        "# config['gen_d_model'] = 256\n",
        "# config['gen_emb_size'] = 768\n",
        "# config['gen_num_heads'] = 4\n",
        "# config['gen_dropout'] = 0.1\n",
        "# config['dis_num_layers'] = 12\n",
        "# config['dis_dff'] = 768 * 4\n",
        "# config['dis_d_model'] = 768\n",
        "# config['dis_emb_size'] = 768\n",
        "# config['dis_num_heads'] = 12\n",
        "# config['dis_dropout'] = 0.1\n",
        "# config['dis_lambda'] = 50\n",
        "# config['batch_size'] = 16\n",
        "# config['lr'] = 3e-5\n",
        "# config['epoch'] = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIS17P63jG1V"
      },
      "outputs": [],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYPyJasmjeoW"
      },
      "outputs": [],
      "source": [
        "n_path = '/content/dataset/next_pred'\n",
        "r_path = '/content/dataset/random_pred'\n",
        "\n",
        "n_path_list, r_path_list = dataset_fn.make_json_list(n_path, r_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95yavytKjx5i",
        "outputId": "4b91b360-1190-4d61-c091-5ce2ec937bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"electra_pretrain\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " generator (Generator)       multiple                  9575936   \n",
            "                                                                 \n",
            " discriminator (Discriminato  multiple                 13763456  \n",
            " r)                                                              \n",
            "                                                                 \n",
            " embedding (Embedding)       multiple                  4121600   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     multiple                  256       \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     multiple                  65664     \n",
            "                                                                 \n",
            " dense_148 (Dense)           multiple                  512       \n",
            "                                                                 \n",
            " dense_149 (Dense)           multiple                  8243200   \n",
            "                                                                 \n",
            " dense_150 (Dense)           multiple                  514       \n",
            "                                                                 \n",
            " activation (Activation)     multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,583,618\n",
            "Trainable params: 31,583,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "if os.path.isdir('/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/weight_folder') == False:\n",
        "  os.mkdir('/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/weight_folder')\n",
        "save_path = '/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/weight_folder/save_small_pretrain.h5'\n",
        "gen_save_path = '/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/weight_folder/gen_save_small_pretrain.h5'\n",
        "dis_save_path = '/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/weight_folder/dis_save_small_pretrain.h5'\n",
        "\n",
        "with strategy.scope():\n",
        "  tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
        "  model = electra.ElectraPretrain(config)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'])\n",
        "  x = tf.range(512*1)\n",
        "  x = tf.reshape(x, shape=(-1, 512))\n",
        "  test_batch_size = x.shape[0]\n",
        "  seg = tf.ones_like(x)\n",
        "  label_cls = tf.ones(shape=(test_batch_size, ))\n",
        "  total_loss, gen_loss, sampling, dis_loss = model([x, seg, label_cls, x])\n",
        "  model.summary()\n",
        "  #model.load_weights(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.mixed_precision.global_policy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9viZXJe0Ds9",
        "outputId": "8aeda598-3c9b-44a4-88f4-f639efb215fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Policy \"mixed_bfloat16\">"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc8XMaGY1uIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a69bbc-6ab9-4181-d46a-9203c7474db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.000134064, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "lr = 2e-4\n",
        "for i in range(10):\n",
        "  lr = lr*tf.math.exp(-0.04)\n",
        "print(lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eReh-zfZk9oV"
      },
      "outputs": [],
      "source": [
        "def train_step(inputs):\n",
        "  sentences, segments, labels_cls, labels_lm = inputs\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    total_loss, gen_loss, sampling, dis_loss = model([sentences, segments, labels_cls, labels_lm], training=True)\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  return tf.reduce_mean(total_loss), tf.reduce_mean(gen_loss), sampling, tf.reduce_mean(dis_loss)\n",
        "\n",
        "@tf.function\n",
        "def distributed_train_step(inputs):\n",
        "  per_total_loss, per_gen_loss, _, per_dis_loss = strategy.run(train_step, args = (inputs, ))\n",
        "  return strategy.reduce(tfd.ReduceOp.MEAN, per_total_loss, axis=None), strategy.reduce(tfd.ReduceOp.MEAN, per_gen_loss, axis=None), strategy.reduce(tfd.ReduceOp.MEAN, per_dis_loss, axis=None)\n",
        "\n",
        "if os.path.isdir('/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/save_index_folder') == False:\n",
        "  os.mkdir('/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/save_index_folder')\n",
        "\n",
        "for epoch in range(config['epoch']):\n",
        "  total_losses = 0.\n",
        "  gen_losses = 0.\n",
        "  dis_losses = 0.\n",
        "  one_batch = 0\n",
        "  n_path_list, r_path_list = dataset_fn.make_json_list(n_path, r_path)\n",
        "  random.shuffle(n_path_list)\n",
        "  random.shuffle(r_path_list)\n",
        "  with open('/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/save_index_folder/n_index.txt', 'w') as n_f:\n",
        "    n_f.writelines(n_path_list)\n",
        "  with open('/content/drive/MyDrive/ColabNotebooks/project/ELECTRA_with_AIHUB_dataset/save_index_folder/r_index.txt', 'w') as r_f:\n",
        "    r_f.writelines(r_path_list)\n",
        "\n",
        "  index_len = len(n_path_list) if len(n_path_list) <= len(r_path_list) else len(r_path_list)\n",
        "  add_connect = False\n",
        "  with tqdm(total=index_len, desc=f\"epoch: {epoch+1}\") as pbar:\n",
        "    for step in range(index_len):\n",
        "      per_sentences, per_segments, per_labels_cls, per_labels_lm  = dataset_fn.make_dataset(step, step, n_path_list, r_path_list, n_path, r_path, config['max_len'], 0)\n",
        "      if add_connect == True:\n",
        "        sentences = np.concatenate([sentences, per_sentences], axis=0)\n",
        "        segments = np.concatenate([segments, per_segments], axis=0)\n",
        "        labels_cls = np.concatenate([labels_cls, per_labels_cls], axis=0)\n",
        "        labels_lm = np.concatenate([labels_lm, per_labels_lm], axis=0)\n",
        "        add_connect = False\n",
        "      else:\n",
        "        sentences = per_sentences\n",
        "        segments = per_segments\n",
        "        labels_cls = per_labels_cls\n",
        "        labels_lm = per_labels_lm\n",
        "      \n",
        "      if len(sentences) < config['batch_size'] and step != (index_len - 1):\n",
        "        add_connect = True\n",
        "        if step % 1700 == 99:\n",
        "          print(f\"epoch: {epoch}, step: {step}, total_loss: {total_losses/one_batch}, gen_loss: {gen_losses/one_batch}, dis_loss: {dis_losses/one_batch}\")\n",
        "          model.save_weights(save_path, overwrite=True)\n",
        "          model.generator.save(gen_save_path)\n",
        "          model.discriminator.save(dis_save_path)\n",
        "        pbar.update(1)\n",
        "        continue\n",
        "\n",
        "      if len(sentences) >= config['batch_size']:\n",
        "        step_epochs = len(sentences) // config['batch_size']\n",
        "        for step_epoch in range(step_epochs):\n",
        "          dataset = tf.data.Dataset.from_tensor_slices((\n",
        "              sentences[step_epoch*config['batch_size']:(step_epoch*config['batch_size']) + config['batch_size']],\n",
        "              segments[step_epoch*config['batch_size']:(step_epoch*config['batch_size']) + config['batch_size']],\n",
        "              labels_cls[step_epoch*config['batch_size']:(step_epoch*config['batch_size']) + config['batch_size']],\n",
        "              labels_lm[step_epoch*config['batch_size']:(step_epoch*config['batch_size']) + config['batch_size']]\n",
        "          ))\n",
        "          dataset = dataset.cache()\n",
        "          dataset = dataset.shuffle(config['batch_size'])\n",
        "          dataset = dataset.batch(config['batch_size'])\n",
        "          dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "          dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "          for x in dataset:\n",
        "            total_loss, gen_loss, dis_loss = distributed_train_step(x)\n",
        "            total_loss = tf.reduce_mean(total_loss)\n",
        "            gen_loss = tf.reduce_mean(gen_loss)\n",
        "            dis_loss = tf.reduce_mean(dis_loss)\n",
        "            one_batch += 1\n",
        "            total_losses += total_loss\n",
        "            gen_losses += gen_loss\n",
        "            dis_losses += dis_loss\n",
        "\n",
        "\n",
        "      if step % 1000 == 99:\n",
        "        print(f\"epoch: {epoch}, step: {step}, total_loss: {total_losses/one_batch}, gen_loss: {gen_losses/one_batch}, dis_loss: {dis_losses/one_batch}\")\n",
        "        model.save_weights(save_path, overwrite=True)\n",
        "        model.generator.save(gen_save_path)\n",
        "        model.discriminator.save(dis_save_path)\n",
        "        #optimizer.learning_rate = optimizer.learning_rate * tf.math.exp(-0.04)        \n",
        "      pbar.update(1)\n",
        "\n",
        "  print(f\"epoch: {epoch+1}, total_loss: {total_losses/one_batch}, gen_loss: {gen_losses/one_batch}, dis_loss: {dis_losses/one_batch}\")\n",
        "  print(\"one epoch end\")\n",
        "  model.save_weights(save_path, overwrite=True)\n",
        "  model.generator.save(gen_save_path)\n",
        "  model.discriminator.save(dis_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uafOvWPnlkau"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}