{"cells":[{"cell_type":"markdown","source":["# data preprcessing step1\n","이 파일은 대용량 데이터를 저장해야 하기 때문에 colab 환경에 아닌, 로컬 환경에서 진행.\n"],"metadata":{"id":"8KeG_VRK3vDc"},"id":"8KeG_VRK3vDc"},{"cell_type":"code","execution_count":null,"id":"1cf93735","metadata":{"id":"1cf93735"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import json\n","import sys\n","import random\n","import copy\n","import transformers\n","import shutil\n","import tqdm\n","\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"id":"a490f5af","metadata":{"id":"a490f5af"},"outputs":[],"source":["def get_dir_size(path): #전체 데이터의 크기를 확인\n","    total = 0\n","    with os.scandir(path) as it:\n","        for entry in it:\n","            if entry.is_file():\n","                total += entry.stat().st_size\n","            elif entry.is_dir():\n","                total += get_dir_size(entry.path)\n","    return total"]},{"cell_type":"code","execution_count":null,"id":"366c8f1f","metadata":{"id":"366c8f1f"},"outputs":[],"source":["def Create_token_json_file(next_num_file=10000, random_num_file=10000):\n","  next_pred_json_list = []\n","  random_pred_json_list = []\n","  if os.path.isdir('/Users/yoon-seunggyu/conda_folder/next_pred') == False:\n","    os.mkdir('/Users/yoon-seunggyu/conda_folder/next_pred') #다음 문장 예측에서 올바르게 예측된 문장들의 집합 폴더\n","  if os.path.isdir('/Users/yoon-seunggyu/conda_folder/random_pred') == False:\n","    os.mkdir('/Users/yoon-seunggyu/conda_folder/random_pred') #다음 문장 예측에서 랜덤하게 연결된 문장들의 집합 폴더\n","  for i in range(next_num_file):\n","    next_pred_json_list.append(f'/Users/yoon-seunggyu/conda_folder/next_pred/{i}.json') #입력된 갯수만큼의 json 파일을 생성\n","  for i in range(random_num_file):\n","    random_pred_json_list.append(f'/Users/yoon-seunggyu/conda_folder/random_pred/{i}.json')\n","\n","  return next_pred_json_list, random_pred_json_list"]},{"cell_type":"code","execution_count":null,"id":"3fb76493","metadata":{"id":"3fb76493"},"outputs":[],"source":["def Init_json_file(file):\n","  news_label = {}\n","  news_label['sentence'] = []\n","  with open(file, 'w') as f:\n","    json.dump(news_label, f, indent='\\t')"]},{"cell_type":"code","execution_count":null,"id":"1b74081c","metadata":{"id":"1b74081c"},"outputs":[],"source":["def Crete_mask(sentence):\n","  mask_sen = copy.deepcopy(sentence)\n","  label_lm = []\n","  for index, en in enumerate(mask_sen):\n","    if index == 0 or index == len(mask_sen) - 1: #[cls], [sep]는 넘어가야함\n","      label_lm.append(-1)\n","      continue\n","    if random.random() < 0.2: #masking prob: 20%\n","      if random.random() < 0.7:\n","        mask_sen[index] = 4 #mask token index: 4\n","      else:\n","        if random.random() > 0.5: #다른 단어로 교체\n","          mask_sen[index] = int(random.random() * 32200)\n","      label_lm.append(sentence[index])\n","    else:\n","      label_lm.append(-1)\n","  return mask_sen, label_lm"]},{"cell_type":"code","execution_count":null,"id":"00cf08bc","metadata":{"id":"00cf08bc"},"outputs":[],"source":["\n","\"\"\"\n","2개 문장 단위로 불러옴.\n","불러온 인덱스가 2로 나눌시 나머지가 0일 경우는 next json 폴더에 저장됨.\n","이 경우 두 문장 모두 같은 폴더에 순서대로 저장.\n","나머지가 1일 경우는 random json 폴더에 저장.\n","이 경우는 다른 2 파일을 불러와 따로 저장함(겹치지 않게 하기 위해).\n","파일이 중복될 확률이 1/random_num_file**2이기 때문에, 확인 코드 없이 진행할 예정\n","news의 길이가 홀수 인 경우, 마지막 문장은 random json 폴더에 저장.\n","\"\"\"\n","def Add_sentence_to_new_json(news, news_label_lms, next_pred_json_list, random_pred_json_list, next_num_file=10000, random_num_file=10000):\n","  news_len = len(news) // 2\n","  odd_bool = True if len(news)%2 == 1 else False\n","  if odd_bool == True: ## news의 길이가 홀수일 경우, random predict로 보내기\n","    file_index = int(random.random() * random_num_file)\n","    news_odd = news[-1]\n","    label_odd = news_label_lms[-1]\n","    data = (news_odd, label_odd)\n","    with open(random_pred_json_list[file_index], 'r') as r_save_file: #read save_file\n","      save_json = json.load(r_save_file)\n","    save_json['sentence'].append(data)\n","    with open(random_pred_json_list[file_index], 'w') as save_file: #save_file\n","      json.dump(save_json, save_file)\n","\n","  for i in range(news_len):\n","    if i % 2 == 0: #next-sentence json으로\n","      file_index = int(random.random() * next_num_file)\n","      news_next1 = news[i*2]\n","      label_next1 = news_label_lms[i*2]\n","      news_next2 = news[i*2 +1]\n","      label_next2 = news_label_lms[i*2 +1]\n","      data1 = [news_next1, label_next1]\n","      data2 = [news_next2, label_next2]\n","      data = (data1, data2)\n","\n","      with open(next_pred_json_list[file_index], 'r') as r_save_file:\n","        save_json = json.load(r_save_file)\n","      save_json['sentence'].append(data)\n","      with open(next_pred_json_list[file_index], 'w') as save_file:\n","        json.dump(save_json, save_file)\n","\n","    else:\n","      file_index1 = int(random.random() * random_num_file)\n","      file_index2 = int(random.random() * random_num_file)\n","      news_next1 = news[i*2]\n","      label_next1 = news_label_lms[i*2]\n","      news_next2 = news[i*2 +1]\n","      label_next2 = news_label_lms[i*2 +1]\n","      data1 = (news_next1, label_next1)\n","      data2 = (news_next2, label_next2)\n","\n","      #2개의 데이터를 연결되지 않게 하기 위해 다른 폴더에 저장. 체크를 따로 하지 않는 이유는 중복되서 저장될 확률이 1/random_num_file**2이기 때문. \n","      with open(random_pred_json_list[file_index1], 'r') as r_save_file1:\n","        save_json1 = json.load(r_save_file1)\n","      with open(random_pred_json_list[file_index2], 'r') as r_save_file2:\n","        save_json2 = json.load(r_save_file2)\n","      save_json1['sentence'].append(data1)\n","      save_json2['sentence'].append(data2)\n","      with open(random_pred_json_list[file_index1], 'w') as save_file1:\n","        json.dump(save_json1, save_file1)\n","      with open(random_pred_json_list[file_index2], 'w') as save_file2:\n","        json.dump(save_json2, save_file2)"]},{"cell_type":"code","execution_count":null,"id":"cd5a7900","metadata":{"id":"cd5a7900","outputId":"ac642471-d7d7-4da1-b635-240abcf89e96"},"outputs":[{"name":"stdout","output_type":"stream","text":["28.961090787Gb\n"]}],"source":["size_result = get_dir_size(\"/Users/yoon-seunggyu/Downloads/030.웹데이터 기반 한국어 말뭉치 데이터/01.데이터/1.Training/라벨링데이터\")\n","print(str(size_result / 1000 ** 3) + \"Gb\") #gb"]},{"cell_type":"code","execution_count":null,"id":"39f87aac","metadata":{"id":"39f87aac"},"outputs":[],"source":["vocab = transformers.BertTokenizer('/Users/yoon-seunggyu/Downloads/vocab.txt', do_lower_case=False, strip_accents=False)"]},{"cell_type":"code","execution_count":null,"id":"6e95b88b","metadata":{"id":"6e95b88b"},"outputs":[],"source":["label_json_path = '/Users/yoon-seunggyu/Downloads/030.웹데이터 기반 한국어 말뭉치 데이터/01.데이터/1.Training/라벨링데이터/TL1'\n","label_list_dir = os.listdir(label_json_path)\n","label_list_dir.remove('.DS_Store')"]},{"cell_type":"code","execution_count":null,"id":"c96c0065","metadata":{"id":"c96c0065"},"outputs":[],"source":["label_list_dir\n","\n","label_dict = {}\n","for label_dir in label_list_dir:\n","  label_dict[label_dir] = os.listdir(label_json_path + '/' + label_dir)"]},{"cell_type":"code","execution_count":null,"id":"8e5121a2","metadata":{"id":"8e5121a2","outputId":"2fbc4087-3180-4702-e60d-eaeecb0d8309"},"outputs":[{"data":{"text/plain":["32200"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["vocab.vocab_size"]},{"cell_type":"code","execution_count":null,"id":"ba4cadc9","metadata":{"id":"ba4cadc9"},"outputs":[],"source":["next_num_file = 10000\n","random_num_file = 10000\n","next_pred_json_list, random_pred_json_list = Create_token_json_file(next_num_file, random_num_file)"]},{"cell_type":"code","execution_count":null,"id":"8192d8e7","metadata":{"id":"8192d8e7"},"outputs":[],"source":["for n_pred, r_pred in zip(next_pred_json_list, random_pred_json_list):\n","  Init_json_file(n_pred)\n","  Init_json_file(r_pred)"]},{"cell_type":"code","execution_count":null,"id":"279766b9","metadata":{"id":"279766b9","outputId":"39a953f8-4974-4ed5-9d78-c13d6ca0f043"},"outputs":[{"name":"stdout","output_type":"stream","text":["취미: 2746(json파일 갯수)\n","스포츠: 2550(json파일 갯수)\n","산업: 4031(json파일 갯수)\n","지역: 3296(json파일 갯수)\n","정치: 3286(json파일 갯수)\n","건강: 3247(json파일 갯수)\n","IT_과학: 1217(json파일 갯수)\n","사회일발: 3474(json파일 갯수)\n","경제: 5072(json파일 갯수)\n","국제: 2162(json파일 갯수)\n","여성복지: 2786(json파일 갯수)\n","교육: 2789(json파일 갯수)\n","문화: 1683(json파일 갯수)\n","여행레저: 3162(json파일 갯수)\n","연예: 4603(json파일 갯수)\n","라이프스타일: 2913(json파일 갯수)\n","사건사고: 2813(json파일 갯수)\n","총 파일 갯수: 51830\n"]}],"source":["sum_file = 0\n","for key, values in label_dict.items(): #종류 단위\n","  print(key + \": \" + str(len(values)) + '(json파일 갯수)')\n","  sum_file += len(values)\n","print(\"총 파일 갯수: \" + str(sum_file))"]},{"cell_type":"code","execution_count":null,"id":"408fe43b","metadata":{"id":"408fe43b"},"outputs":[],"source":["for key, values in label_dict.items(): #종류 단위\n","  print(key + \": \" + str(len(values)) + '(json파일 갯수)')\n","  with tqdm(total=len(values), desc=f\"{key} 진행도: \") as pbar:\n","    for value_len, value in enumerate(values): #기사가 포함되어 있는 파일 하나씩\n","      with open(label_json_path + '/' + key + '/' + value, 'r') as f: \n","        json_data = json.load(f)\n","        len_named = len(json_data['named_entity']) #-> 0 ~ len_named // 2 -1 안의 무작위 값을 random으로 받아오기(vocab으로 변환 후 길이로 해야함)\n","        for named_entity in json_data['named_entity']: #한 파일안의 기사 하나씩 꺼내기\n","          contents = named_entity['content']\n","          news = []\n","          temp_news = []\n","          news_label_lms = []\n","          temp_news_label_lms = []\n","          for content in contents: #기사 내의 한문장씩\n","            sentence = content['sentence'] # -> vocab으로 변환하여, 255까지 채울 수 있도록 하기(bos, eos, sep 토큰도 들어가야하기 때문)\n","            sentence = vocab.encode(sentence)\n","            sentence, label_lm = Crete_mask(sentence)\n","            if len(sentence) + len(temp_news) > 254:\n","              temp_news += [3] #[sep] token 붙이기 \n","              temp_news_label_lms += [-1]\n","              news.append(temp_news)\n","              news_label_lms.append(temp_news_label_lms)\n","              temp_news = []\n","              temp_news_label_lms = []\n","              temp_news += sentence[:-1]\n","              temp_news_label_lms += label_lm[1:-1]\n","            else:\n","              temp_news += sentence[1:-1]\n","              temp_news_label_lms += label_lm[1:-1]\n","          Add_sentence_to_new_json(news, news_label_lms, next_num_file, random_num_file, next_pred_json_list, random_pred_json_list)\n","      pbar.update(1)"]},{"cell_type":"code","execution_count":null,"id":"95a4264b","metadata":{"id":"95a4264b"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"data_processing.ipynb","language":"python","name":"first_en"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"name":"data_preprocessing.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}
